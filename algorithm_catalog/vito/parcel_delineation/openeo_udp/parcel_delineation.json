{
  "process_graph": {
    "loadcollection1": {
      "process_id": "load_collection",
      "arguments": {
        "bands": [
          "B04",
          "B08"
        ],
        "id": "SENTINEL2_L2A",
        "properties": {
          "eo:cloud_cover": {
            "process_graph": {
              "lte1": {
                "process_id": "lte",
                "arguments": {
                  "x": {
                    "from_parameter": "value"
                  },
                  "y": 10
                },
                "result": true
              }
            }
          }
        },
        "spatial_extent": {
          "from_parameter": "spatial_extent"
        },
        "temporal_extent": {
          "from_parameter": "temporal_extent"
        }
      }
    },
    "loadcollection2": {
      "process_id": "load_collection",
      "arguments": {
        "bands": [
          "SCL"
        ],
        "id": "SENTINEL2_L2A",
        "properties": {
          "eo:cloud_cover": {
            "process_graph": {
              "lte2": {
                "process_id": "lte",
                "arguments": {
                  "x": {
                    "from_parameter": "value"
                  },
                  "y": 10
                },
                "result": true
              }
            }
          }
        },
        "spatial_extent": {
          "from_parameter": "spatial_extent"
        },
        "temporal_extent": {
          "from_parameter": "temporal_extent"
        }
      }
    },
    "toscldilationmask1": {
      "process_id": "to_scl_dilation_mask",
      "arguments": {
        "data": {
          "from_node": "loadcollection2"
        },
        "erosion_kernel_size": 3,
        "kernel1_size": 17,
        "kernel2_size": 77,
        "mask1_values": [
          2,
          4,
          5,
          6,
          7
        ],
        "mask2_values": [
          3,
          8,
          9,
          10,
          11
        ]
      }
    },
    "mask1": {
      "process_id": "mask",
      "arguments": {
        "data": {
          "from_node": "loadcollection1"
        },
        "mask": {
          "from_node": "toscldilationmask1"
        }
      }
    },
    "ndvi1": {
      "process_id": "ndvi",
      "arguments": {
        "data": {
          "from_node": "mask1"
        },
        "nir": "B08",
        "red": "B04"
      }
    },
    "applyneighborhood1": {
      "process_id": "apply_neighborhood",
      "arguments": {
        "data": {
          "from_node": "ndvi1"
        },
        "overlap": [
          {
            "dimension": "x",
            "value": 32,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 32,
            "unit": "px"
          }
        ],
        "process": {
          "process_graph": {
            "runudf1": {
              "process_id": "run_udf",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                },
                "runtime": "Python",
                "udf": "from functools import lru_cache\nimport gc\nimport sys\nfrom typing import Dict, Tuple\nfrom random import seed, sample\nfrom xarray import DataArray, zeros_like\nfrom openeo.udf import inspect\n\n# Add the onnx dependencies to the path\nsys.path.insert(1, \"onnx_deps\")\nimport onnxruntime as ort\n\n\nmodel_names = frozenset(\n    [\n        \"BelgiumCropMap_unet_3BandsGenerator_Network1.onnx\",\n        \"BelgiumCropMap_unet_3BandsGenerator_Network2.onnx\",\n        \"BelgiumCropMap_unet_3BandsGenerator_Network3.onnx\",\n    ]\n)\n\n\n@lru_cache(maxsize=1)\ndef load_ort_sessions(names):\n    \"\"\"\n    Load the models and make the prediction functions.\n    The lru_cache avoids loading the model multiple times on the same worker.\n\n    @param modeldir: Model directory\n    @return: Loaded model sessions\n    \"\"\"\n    # inspect(message=\"Loading convolutional neural networks as ONNX runtime sessions ...\")\n    return [ort.InferenceSession(f\"onnx_models/{model_name}\") for model_name in names]\n\n\ndef process_window_onnx(ndvi_stack: DataArray, patch_size=128) -> DataArray:\n    \"\"\"Compute prediction.\n\n    Compute predictions using ML models. ML models takes three inputs images and predicts\n    one image. Four predictions are made per model using three random images. Three images\n    are considered to save computational time. Final result is median of these predictions.\n\n    Parameters\n    ----------\n    ndvi_stack : DataArray\n        ndvi data\n    patch_size : Int\n        Size of the sample\n\n    Returns\n    -------\n    xr.DataArray\n        Machine learning prediction.\n    \"\"\"\n    # Do 12 predictions: use 3 networks, and for each take 3 random NDVI images and repeat 4 times\n    ort_sessions = load_ort_sessions(model_names)  # get models\n\n    predictions_per_model = 4\n    no_rand_images = 3  # Number of random images that are needed for input\n    no_images = ndvi_stack.t.shape[0]\n\n    # Range of index of images for random index selection\n    images_range = range(no_images)\n    # List of all predictions\n    prediction = []\n    for ort_session in ort_sessions:\n        # make 4 predictions per model\n        for i in range(predictions_per_model):\n            # initialize a predicter array\n            # Seed to lead to a reproducible results.\n            seed(i)\n            # Random selection of 3 images for input\n            idx = sample(images_range, k=no_rand_images)\n            # log a message that the selected indices are not at least a week away\n            if len(set((ndvi_stack.isel(t=idx)).t.dt.isocalendar().week.data)) != no_rand_images:\n                inspect(message=\"Time difference is not larger than a week for good parcel delineation\")\n\n            # re-shape the input data for ML input\n            input_data = ndvi_stack.isel(t=idx).data.reshape(1, patch_size * patch_size, no_rand_images)\n            ort_inputs = {ort_session.get_inputs()[0].name: input_data}\n\n            # Run ML to predict\n            ort_outputs = ort_session.run(None, ort_inputs)\n            # reshape ort_outputs and append it to prediction list\n            prediction.append(ort_outputs[0].reshape((patch_size, patch_size)))\n\n    # free up some memory to avoid memory errors\n    gc.collect()\n\n    # Create a DataArray of all predictions\n    all_predictions = DataArray(\n        prediction,\n        dims=[\"predict\", \"x\", \"y\"],\n        coords={\n            \"predict\": range(len(prediction)),\n            \"x\": ndvi_stack.coords[\"x\"],\n            \"y\": ndvi_stack.coords[\"y\"],\n        },\n    )\n    # final prediction is the median of all predictions per pixel\n    return all_predictions.median(dim=\"predict\")\n\n\ndef get_valid_ml_inputs(nvdi_stack_data: DataArray, sum_invalid, min_images: int) -> DataArray:\n    \"\"\"Machine learning inputs\n\n    Extract ML inputs based on how good the data is\n\n    \"\"\"\n    if (sum_invalid.data == 0).sum() >= min_images:\n        good_data = nvdi_stack_data.sel(t=sum_invalid[sum_invalid.data == 0].t)\n    else:  # select the 4 best time samples with least amount of invalid pixels.\n        good_data = nvdi_stack_data.sel(t=sum_invalid.sortby(sum_invalid).t[:min_images])\n    return good_data\n\n\ndef preprocess_datacube(cubearray: DataArray, min_images: int) -> Tuple[bool, DataArray]:\n    \"\"\"Preprocess data for machine learning.\n\n    Preprocess data by clamping NVDI values and first check if the\n    data is valid for machine learning and then check if there is good\n    data to perform machine learning.\n\n    Parameters\n    ----------\n    cubearray : xr.DataArray\n        Input datacube\n    min_images : int\n        Minimum number of samples to consider for machine learning.\n\n    Returns\n    -------\n    bool\n        True refers to data is invalid for machine learning.\n    xr.DataArray\n        If above bool is False, return data for machine learning else returns a\n        sample containing nan (similar to machine learning output).\n    \"\"\"\n    # Preprocessing data\n    # check if bands is in the dims and select the first index\n    if \"bands\" in cubearray.dims:\n        nvdi_stack = cubearray.isel(bands=0)\n    else:\n        nvdi_stack = cubearray\n    # Clamp out of range NDVI values\n    nvdi_stack = nvdi_stack.where(lambda nvdi_stack: nvdi_stack < 0.92, 0.92)\n    nvdi_stack = nvdi_stack.where(lambda nvdi_stack: nvdi_stack > -0.08)\n    nvdi_stack += 0.08\n    # Count the amount of invalid pixels in each time sample.\n    sum_invalid = nvdi_stack.isnull().sum(dim=[\"x\", \"y\"])\n    # Check % of invalid pixels in each time sample by using mean\n    sum_invalid_mean = nvdi_stack.isnull().mean(dim=[\"x\", \"y\"])\n    # Fill the invalid pixels with value 0\n    nvdi_stack_data = nvdi_stack.fillna(0)\n\n    # Check if data is valid for machine learning. If invalid, return True and\n    # an DataArray of nan values (similar to the machine learning output)\n    # The number of invalid time sample less then min images\n    if (sum_invalid_mean.data < 1).sum() <= min_images:\n        inspect(message=\"Input data is invalid for this window -> skipping!\")\n        # create a nan dataset and return\n        nan_data = zeros_like(nvdi_stack.sel(t=sum_invalid_mean.t[0], drop=True))\n        nan_data = nan_data.where(lambda nan_data: nan_data > 1)\n        return True, nan_data\n    # Data selection: valid data for machine learning\n    # select time samples where there are no invalid pixels\n    good_data = get_valid_ml_inputs(nvdi_stack_data, sum_invalid, min_images)\n    return False, good_data.transpose(\"x\", \"y\", \"t\")\n\n\ndef apply_datacube(cube: DataArray, context: Dict) -> DataArray:\n    # select atleast best 4 temporal images of ndvi for ML\n    min_images = 4\n    # preprocess the datacube\n    invalid_data, ndvi_stack = preprocess_datacube(cube, min_images)\n    # If data is invalid, there is no need to run prediction algorithm so\n    # return prediction as nan DataArray and reintroduce time and bands dimensions\n    if invalid_data:\n        return ndvi_stack.expand_dims(dim={\"t\": [(cube.t.dt.year.values[0])], \"bands\": [\"prediction\"]})\n    # Machine learning prediction: process the window\n    result = process_window_onnx(ndvi_stack)\n    # Reintroduce time and bands dimensions\n    result_xarray = result.expand_dims(dim={\"t\": [(cube.t.dt.year.values[0])], \"bands\": [\"prediction\"]})\n    # Return the resulting xarray\n    return result_xarray\n"
              },
              "result": true
            }
          }
        },
        "size": [
          {
            "dimension": "x",
            "value": 64,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 64,
            "unit": "px"
          }
        ]
      }
    },
    "applyneighborhood2": {
      "process_id": "apply_neighborhood",
      "arguments": {
        "data": {
          "from_node": "applyneighborhood1"
        },
        "overlap": [
          {
            "dimension": "x",
            "value": 0,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 0,
            "unit": "px"
          }
        ],
        "process": {
          "process_graph": {
            "runudf2": {
              "process_id": "run_udf",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                },
                "runtime": "Python",
                "udf": "from xarray import DataArray\nfrom skimage import segmentation, graph\nfrom skimage.filters import sobel\nfrom typing import Dict\nfrom openeo.udf import inspect\n\n\ndef apply_datacube(cube: DataArray, context: Dict) -> DataArray:\n    inspect(message=f\"Dimensions of the final datacube {cube.dims}\")\n    # get the underlying array without the bands and t dimension\n    image_data = cube.squeeze(\"t\", drop=True).squeeze(\"bands\", drop=True).values\n    # compute edges\n    edges = sobel(image_data)\n    # Perform felzenszwalb segmentation\n    segment = segmentation.felzenszwalb(image_data, scale=120, sigma=0.0, min_size=30, channel_axis=None)\n    # Perform the rag boundary analysis and merge the segments\n    bgraph = graph.rag_boundary(segment, edges)\n    # merging segments\n    mergedsegment = graph.cut_threshold(segment, bgraph, 0.15, in_place=False)\n    # create a data cube and perform masking operations\n    output_arr = DataArray(mergedsegment.reshape(cube.shape), dims=cube.dims, coords=cube.coords)\n    output_arr = output_arr.where(cube >= 0.3)   # Mask the output pixels based on the cube values <0.3\n    output_arr = output_arr.where(output_arr >= 0)  # Mask all values less than or equal to zero\n    return output_arr\n"
              },
              "result": true
            }
          }
        },
        "size": [
          {
            "dimension": "x",
            "value": 2048,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 2048,
            "unit": "px"
          }
        ]
      },
      "result": true
    }
  },
  "id": "parcel_delineation",
  "summary": "Parcel delineation using Sentinel-2 data retrieved from the CDSE and processed on openEO.",
  "description": "Parcel delineation using Sentinel-2",
  "default_job_options": {
    "udf-dependency-archives": [
      "https://artifactory.vgt.vito.be/auxdata-public/openeo/onnx_dependencies.zip#onnx_deps",
      "https://artifactory.vgt.vito.be/artifactory/auxdata-public/openeo/parcelDelination/BelgiumCropMap_unet_3BandsGenerator_Models.zip#onnx_models"
    ],
    "driver-memory": "500m",
    "driver-memoryOverhead": "1000m",
    "executor-memory": "1000m",
    "executor-memoryOverhead": "500m",
    "python-memory": "4200m"
  },
  "parameters": [
    {
      "name": "spatial_extent",
      "description": "Spatial extent specified as a bounding box with 'west', 'south', 'east' and 'north' fields.",
      "schema": {
        "type": "object",
        "subtype": "bounding-box",
        "required": [
          "west",
          "south",
          "east",
          "north"
        ],
        "properties": {
          "west": {
            "type": "number",
            "description": "West (lower left corner, coordinate axis 1)."
          },
          "south": {
            "type": "number",
            "description": "South (lower left corner, coordinate axis 2)."
          },
          "east": {
            "type": "number",
            "description": "East (upper right corner, coordinate axis 1)."
          },
          "north": {
            "type": "number",
            "description": "North (upper right corner, coordinate axis 2)."
          },
          "crs": {
            "description": "Coordinate reference system of the extent, specified as as [EPSG code](http://www.epsg-registry.org/) or [WKT2 CRS string](http://docs.opengeospatial.org/is/18-010r7/18-010r7.html). Defaults to `4326` (EPSG code 4326) unless the client explicitly requests a different coordinate reference system.",
            "anyOf": [
              {
                "type": "integer",
                "subtype": "epsg-code",
                "title": "EPSG Code",
                "minimum": 1000
              },
              {
                "type": "string",
                "subtype": "wkt2-definition",
                "title": "WKT2 definition"
              }
            ],
            "default": 4326
          }
        }
      },
      "default": {
        "west": 5.0,
        "south": 51.2,
        "east": 5.1,
        "north": 51.3
      },
      "optional": true
    },
    {
      "name": "temporal_extent",
      "description": "Temporal extent specified as two-element array with start and end date/date-time.",
      "schema": {
        "type": "array",
        "subtype": "temporal-interval",
        "uniqueItems": true,
        "minItems": 2,
        "maxItems": 2,
        "items": {
          "anyOf": [
            {
              "type": "string",
              "subtype": "date-time",
              "format": "date-time"
            },
            {
              "type": "string",
              "subtype": "date",
              "format": "date"
            },
            {
              "type": "null"
            }
          ]
        }
      },
      "default": [
        "2021-01-01",
        "2021-12-31"
      ],
      "optional": true
    }
  ]
}