{
  "process_graph": {
    "loadcollection1": {
      "process_id": "load_collection",
      "arguments": {
        "bands": [
          "B04",
          "B08"
        ],
        "id": "SENTINEL2_L2A",
        "properties": {
          "eo:cloud_cover": {
            "process_graph": {
              "lte1": {
                "process_id": "lte",
                "arguments": {
                  "x": {
                    "from_parameter": "value"
                  },
                  "y": 10
                },
                "result": true
              }
            }
          }
        },
        "spatial_extent": {
          "from_parameter": "spatial_extent"
        },
        "temporal_extent": {
          "from_parameter": "temporal_extent"
        }
      }
    },
    "ndvi1": {
      "process_id": "ndvi",
      "arguments": {
        "data": {
          "from_node": "loadcollection1"
        },
        "nir": "B08",
        "red": "B04"
      }
    },
    "applyneighborhood1": {
      "process_id": "apply_neighborhood",
      "arguments": {
        "data": {
          "from_node": "ndvi1"
        },
        "overlap": [
          {
            "dimension": "x",
            "value": 32,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 32,
            "unit": "px"
          }
        ],
        "process": {
          "process_graph": {
            "runudf1": {
              "process_id": "run_udf",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                },
                "runtime": "Python",
                "udf": "# /// script\n# dependencies = [\n# \"onnxruntime\",\n# ]\n# ///\n\nimport functools\nimport gc\nimport sys\nimport os\nfrom typing import Dict\nimport random\nimport openeo\nimport xarray as xr\nfrom openeo.udf import inspect\nimport requests\nimport zipfile\nimport onnxruntime as ort\n\n\nmodel_names = frozenset([\n    \"BelgiumCropMap_unet_3BandsGenerator_Network1.onnx\",\n    \"BelgiumCropMap_unet_3BandsGenerator_Network2.onnx\",\n    \"BelgiumCropMap_unet_3BandsGenerator_Network3.onnx\",\n])\n\n# Fixed directories for dependencies and model files\nMODEL_DIR = \"model_files\"\n\n\ndef download_file(url, path):\n    \"\"\"\n    Downloads a file from the given URL to the specified path.\n    \"\"\"\n    response = requests.get(url, stream=True)\n    with open(path, \"wb\") as file:\n        file.write(response.content)\n\n\ndef extract_zip(zip_path, extract_to):\n    \"\"\"\n    Extracts a zip file from zip_path to the specified extract_to directory.\n    \"\"\"\n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n        zip_ref.extractall(extract_to)\n    os.remove(zip_path)  # Clean up the zip file after extraction\n\n\ndef add_directory_to_sys_path(directory):\n    \"\"\"\n    Adds a directory to the Python sys.path if it's not already present.\n    \"\"\"\n    if directory not in sys.path:\n        sys.path.insert(0, directory)\n\n\n@functools.lru_cache(maxsize=5)\ndef setup_model_and_dependencies(model_url):\n    \"\"\"\n    Main function to set up the model and dependencies by downloading, extracting,\n    and adding necessary directories to sys.path.\n    \"\"\"\n    inspect(message=\"Create directories\")\n    # Ensure base directories exist\n    os.makedirs(MODEL_DIR, exist_ok=True)\n    # Download and extract model if not already present\n    # if the drectory is empty\n    if not os.listdir(MODEL_DIR):\n        zip_path = os.path.join(MODEL_DIR, \"temp.zip\")\n        download_file(model_url, zip_path)\n        extract_zip(zip_path, MODEL_DIR)\n        # Add the extracted dependencies directory to sys.path\n        add_directory_to_sys_path(MODEL_DIR)\n\n\nsetup_model_and_dependencies(\n    model_url=\"https://artifactory.vgt.vito.be:443/artifactory/auxdata-public/openeo/parcelDelination/BelgiumCropMap_unet_3BandsGenerator_Models.zip\")\n\n\n@functools.lru_cache(maxsize=1)\ndef load_ort_sessions(names):\n    \"\"\"\n    Load the models and make the prediction functions.\n    The lru_cache avoids loading the model multiple times on the same worker.\n\n    @param modeldir: Model directory\n    @return: Loaded model sessions\n    \"\"\"\n    # inspect(message=\"Loading convolutional neural networks as ONNX runtime sessions ...\")\n    return [\n        ort.InferenceSession(f\"{MODEL_DIR}/{model_name}\")\n        for model_name in names\n    ]\n\n\ndef process_window_onnx(ndvi_stack: xr.DataArray, patch_size=128):\n    \"\"\"Compute predictions.\n\n    Compute predictions using ML models. ML models takes three inputs images and predicts\n    one image. Four predictions are made per model using three random images. Three images\n    are considered to save computational time. Final result is median of these predictions.\n\n    Parameters\n    ----------\n    ndvi_stack : DataArray\n        ndvi data\n    patch_size : Int\n        Size of the sample\n\n    \"\"\"\n    # we'll do 12 predictions: use 3 networks, and for each random take 3 NDVI images and repeat 4 times\n    ort_sessions = load_ort_sessions(model_names)    # get models\n\n    predictions_per_model = 4\n    no_rand_images = 3          # Number of random images that are needed for input\n    no_images = ndvi_stack.t.shape[0]\n    \n    # Range of index of images\n    _range = range(no_images)\n    # List of all predictions\n    prediction = []\n    for ort_session in ort_sessions:\n        # make 4 predictions per model\n        for i in range(predictions_per_model):\n            # initialize a predicter array\n            random.seed(i)   # without seed we will have a random number leading to non-reproducible results.\n            _idx = random.choices(_range, k=no_rand_images) # Random selection of 3 images for input\n            # re-shape the input data for ML input \n            input_data = ndvi_stack.isel(t=_idx).data.reshape(1, patch_size * patch_size, no_rand_images)\n            ort_inputs = {ort_session.get_inputs()[0].name: input_data}\n\n            # Run ML to predict\n            ort_outputs = ort_session.run(None, ort_inputs)\n            # reshape ort_outputs and append it to prediction list\n            prediction.append(ort_outputs[0].reshape((patch_size, patch_size)))\n\n    # free up some memory to avoid memory errors\n    gc.collect()\n\n    # Create a DataArray of all predictions\n    all_predictions = xr.DataArray(prediction, dims=[\"predict\", \"x\", \"y\"],\n                                   coords={\"predict\": range(len(prediction)),\n                                           \"x\": ndvi_stack.coords[\"x\"],\n                                           \"y\": ndvi_stack.coords[\"y\"]}\n                                   )\n    # final prediction is the median of all predictions per pixel\n    return all_predictions.median(dim=\"predict\")\n\n\ndef preprocess_datacube(cubearray: xr.DataArray, min_images: int) -> tuple[bool, xr.DataArray]:\n    \"\"\"Preprocess data for machine learning.\n\n    Preprocess data by clamping NVDI values and first check if the\n    data is valid for machine learning and then check if there is good\n    data to perform machine learning.\n\n    Parameters\n    ----------\n    cubearray : xr.DataArray\n        Input datacube\n    min_images : int\n        Minimum number of samples to consider for machine learning.\n\n    Returns\n    -------\n    bool\n        True refers to data is invalid for machine learning.\n    xr.DataArray\n        If above bool is False, return data for machine learning else returns a\n        sample containing nan (similar to machine learning output).\n    \"\"\"\n    # Preprocessing data\n    # check if bands is in the dims and select the first index\n    if \"bands\" in cubearray.dims:\n        nvdi_stack = cubearray.isel(bands=0)\n    else:\n        nvdi_stack = cubearray\n    # Clamp out of range NDVI values\n    nvdi_stack = nvdi_stack.where(lambda nvdi_stack: nvdi_stack < 0.92, 0.92)\n    nvdi_stack = nvdi_stack.where(lambda nvdi_stack: nvdi_stack > -0.08)\n    nvdi_stack += 0.08\n    # Count the amount of invalid pixels in each time sample. \n    sum_invalid = nvdi_stack.isnull().sum(dim=['x', 'y'])\n    # Check % of invalid pixels in each time sample by using mean\n    sum_invalid_mean = nvdi_stack.isnull().mean(dim=['x', 'y'])\n    # Fill the invalid pixels with value 0\n    nvdi_stack_data = nvdi_stack.fillna(0)\n\n    # Check if data is valid for machine learning. If invalid, return True and\n    # an DataArray of nan values (similar to the machine learning output)\n    if (sum_invalid_mean.data < 1).sum() <= min_images:   # number of invalid time sample less then min images\n        inspect(message=\"Input data is invalid for this window -> skipping!\")\n        # create a nan dataset and return\n        nan_data = xr.zeros_like(nvdi_stack.sel(t = sum_invalid_mean.t[0], drop=True))\n        nan_data = nan_data.where(lambda nan_data: nan_data > 1)\n        return True, nan_data\n\n    # Data selection: valid data for machine learning\n    # select time samples where there are no invalid pixels\n    if (sum_invalid.data == 0).sum() >= min_images:\n        good_data = nvdi_stack_data.sel(t = sum_invalid[sum_invalid.data == 0].t)\n    else:      # select the 4 best time samples with least amount of invalid pixels.\n        good_data = nvdi_stack_data.sel(t = sum_invalid.sortby(sum_invalid).t[:min_images])\n    return False, good_data.transpose(\"x\", \"y\", \"t\")\n\n\ndef apply_datacube(cube: xr.DataArray, context: Dict) -> xr.DataArray:\n    # select atleast best 4 temporal images of ndvi for ML\n    min_images = 4\n    \n    inspect(message=\"START Preprocessing Done!\")    \n    # preprocess the datacube\n    invalid_data, ndvi_stack = preprocess_datacube(cube, min_images)\n    inspect(message=\"Preprocessing Done!\")\n    \n    # If data is invalid, there is no need to run prediction algorithm so\n    # return prediction as nan DataArray and reintroduce time and bands dimensions \n    if invalid_data:\n        return ndvi_stack.expand_dims(dim={\"t\": [(cube.t.dt.year.values[0])], \"bands\": [\"prediction\"]})\n\n    inspect(message=\"START ML!\")    \n    # Machine learning prediction: process the window\n    result = process_window_onnx(ndvi_stack)\n    inspect(message=\"End ML!\")\n    # Reintroduce time and bands dimensions\n    result_xarray = result.expand_dims(dim={\"t\": [(cube.t.dt.year.values[0])], \"bands\": [\"prediction\"]})\n    # Return the resulting xarray\n    return result_xarray\n"
              },
              "result": true
            }
          }
        },
        "size": [
          {
            "dimension": "x",
            "value": 64,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 64,
            "unit": "px"
          }
        ]
      }
    },
    "applyneighborhood2": {
      "process_id": "apply_neighborhood",
      "arguments": {
        "data": {
          "from_node": "applyneighborhood1"
        },
        "overlap": [
          {
            "dimension": "x",
            "value": 0,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 0,
            "unit": "px"
          }
        ],
        "process": {
          "process_graph": {
            "runudf2": {
              "process_id": "run_udf",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                },
                "runtime": "Python",
                "udf": "from xarray import DataArray\nfrom skimage import segmentation, graph\nfrom skimage.filters import sobel\nfrom typing import Dict\n\n\ndef apply_datacube(cube: DataArray, context: Dict) -> DataArray:\n    # get the underlying array without the bands and t dimension\n    _data = cube.squeeze(\"t\", drop=True).squeeze(\"bands\", drop=True).values\n    # compute edges\n    edges = sobel(_data)\n    # Perform felzenszwalb segmentation\n    segment = segmentation.felzenszwalb(_data, scale=120, sigma=0.0, min_size=30, channel_axis=None)\n    # Perform the rag boundary analysis and merge the segments\n    bgraph = graph.rag_boundary(segment, edges)\n    # merging segments\n    mergedsegment = graph.cut_threshold(segment, bgraph, 0.15, in_place=False)\n    # create a data cube and perform masking operations\n    output_arr = DataArray(mergedsegment.reshape(cube.shape), dims=cube.dims, coords=cube.coords)\n    output_arr = output_arr.where(cube >= 0.3)   # Mask the output pixels based on the cube values <0.3\n    output_arr = output_arr.where(output_arr >= 0)  # Mask all values less than or equal to zero\n    return output_arr\n"
              },
              "result": true
            }
          }
        },
        "size": [
          {
            "dimension": "x",
            "value": 2048,
            "unit": "px"
          },
          {
            "dimension": "y",
            "value": 2048,
            "unit": "px"
          }
        ]
      },
      "result": true
    }
  },
  "id": "Parcel Delineation",
  "summary": "Parcel delineation using Sentinel-2 data retrieved from the CDSE and processed on openEO.",
  "description": "Parcel delineation using Sentinel-2",
  "parameters": [
    {
      "name": "spatial_extent",
      "description": "Spatial extent specified as a bounding box with 'west', 'south', 'east' and 'north' fields.",
      "schema": {
        "type": "object",
        "subtype": "bounding-box",
        "required": [
          "west",
          "south",
          "east",
          "north"
        ],
        "properties": {
          "west": {
            "type": "number",
            "description": "West (lower left corner, coordinate axis 1)."
          },
          "south": {
            "type": "number",
            "description": "South (lower left corner, coordinate axis 2)."
          },
          "east": {
            "type": "number",
            "description": "East (upper right corner, coordinate axis 1)."
          },
          "north": {
            "type": "number",
            "description": "North (upper right corner, coordinate axis 2)."
          },
          "crs": {
            "description": "Coordinate reference system of the extent, specified as as [EPSG code](http://www.epsg-registry.org/) or [WKT2 CRS string](http://docs.opengeospatial.org/is/18-010r7/18-010r7.html). Defaults to `4326` (EPSG code 4326) unless the client explicitly requests a different coordinate reference system.",
            "anyOf": [
              {
                "type": "integer",
                "subtype": "epsg-code",
                "title": "EPSG Code",
                "minimum": 1000
              },
              {
                "type": "string",
                "subtype": "wkt2-definition",
                "title": "WKT2 definition"
              }
            ],
            "default": 4326
          }
        }
      },
      "default": {
        "west": 5.0,
        "south": 51.2,
        "east": 5.1,
        "north": 51.3
      },
      "optional": true
    },
    {
      "name": "temporal_extent",
      "description": "Temporal extent specified as two-element array with start and end date/date-time.",
      "schema": {
        "type": "array",
        "subtype": "temporal-interval",
        "uniqueItems": true,
        "minItems": 2,
        "maxItems": 2,
        "items": {
          "anyOf": [
            {
              "type": "string",
              "subtype": "date-time",
              "format": "date-time"
            },
            {
              "type": "string",
              "subtype": "date",
              "format": "date"
            },
            {
              "type": "null"
            }
          ]
        }
      },
      "default": [
        "2021-01-01",
        "2021-12-31"
      ],
      "optional": true
    }
  ]
}